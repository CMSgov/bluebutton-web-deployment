#!/bin/bash
##################################################
# Secure Postgres Backup
# v1.0.4 7/31/2017 @ekivemark
# v1.0.4: set aws credentials for cron job
# v1.0.3: add $1 variable to filename record move in separate logs
# v1.0.2: use export var for backup PG_TEMP_DIR
# v1.0.1: add PGPASSFILE and .pgpass
##################################################
# {{ db_server_data_dir }}/db_backup.sh
# Via template hhs_ansible/roles/postgres/templates/db_backup.sh.j2
# Source: s3://bb-config/all_env/db/db_backup.sh
# Parameter 1: hourly, daily, weekly, monthly
##################################################
NOW=$(date +"%Y%m%d_%H%M%S")
export PG_TEMP_DIR={{ db_server_temp_dir }}
export AWS_CONFIG_FILE=/root/.aws/config
export AWS_ACCESS_KEY_ID={{ cf_data_db_backup_key_id  }}
export AWS_SECRET_ACCESS_KEY={{ cf_data_db_backup_secret_key }}
export AWS_DEFAULT_REGION={{ cf_region }}
DB_USER={{ cf_data_pgsql_master }}
PG_ENVIRONMENT={{ cf_data_tag_key_stack }}
DB_TABLE_NAME={{ db_server_table_name }}
# Get HOST_IP
# MAC_ADDR=`curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/`
# HOST_IP=`curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/$MAC_ADDR/local-ipv4s/`
HOST_IP={{ ansible_eth0.ipv4.address }}
PG_ACCESSPORT={{ db_host_port }}
PG_DATA_DIR={{ db_server_data_dir }}

# Patch to force folders to be created for $1 in S3
FREQ_MODE="$1"
echo "$PG_ENVIRONMENT $FREQ_MODE" >$PG_TEMP_DIR/folder_$FREQ_MODE.txt
/usr/local/bin/aws s3 cp $PG_TEMP_DIR/folder_$FREQ_MODE.txt s3://bb-dbback-$PG_ENVIRONMENT/$FREQ_MODE/

# export PGPASSWORD="R3s3t_Th1s"
export PGPASSFILE=$PG_DATA_DIR/.pgpass
# Get password from .pgpass file
echo "Postgres backup: $NOW $PG_ENVIRONMENT:$DB_TABLE_NAME on $HOST_IP:$PG_ACCESSPORT Mode:$1 for $DB_USER started:$NOW" >>$PG_TEMP_DIR/proc.log
echo "Postgres backup: $NOW $PG_ENVIRONMENT:$DB_TABLE_NAME on $HOST_IP:$PG_ACCESSPORT Mode:$1 for $DB_USER started:$NOW" >$PG_TEMP_DIR/latest.log

cd $PG_TEMP_DIR
/usr/pgsql-9.6/bin/pg_dump -U $DB_USER -h $HOST_IP -p {{ db_host_port }} $DB_TABLE_NAME | /usr/bin/bzip2 | /usr/bin/openssl smime -encrypt -aes256 -binary -outform DEM -out $PG_TEMP_DIR/$HOST_IP.$DB_TABLE_NAME.$1_$NOW.sql.bz2.ssl {{ db_server_data_dir }}/{{ db_server_backup_pub_key }}
/usr/local/bin/aws s3 mv $PG_TEMP_DIR/$HOST_IP.$DB_TABLE_NAME.$1_$NOW.sql.bz2.ssl s3://bb-dbback-$PG_ENVIRONMENT/$1/

# Add cleanup process in case move failed
( "$PG_DATA_DIR/db_cleanup.sh" "$1" "db_backup" )

echo "Moved: $HOST_IP.$DB_TABLE_NAME.$1_$NOW.sql.bz2.ssl" >>$PG_TEMP_DIR/moved_$1.log
echo "Transferred: $HOST_IP.$DB_TABLE_NAME.$1_$NOW.sql.bz2.ssl" >>$PG_TEMP_DIR/xfered_$1.log

# If file was moved we should get a file not found message appended to moved_$1.log
ls -la $HOST_IP.$DB_TABLE_NAME.$1_$NOW.sql.bz2.ssl >>$PG_TEMP_DIR/moved_$1.log

NOW_ENDED=$(date +"%Y%m%d_%H%M%S")
echo "Postgres backup: $NOW $PG_ENVIRONMENT:$HOST_IP.$DB_TABLE_NAME on $HOST_IP:$PG_ACCESSPORT Mode:$1 for $DB_USER completed:$NOW_ENDED" >>$PG_TEMP_DIR/proc.log
echo "Postgres backup: $NOW $PG_ENVIRONMENT:$HOST_IP.$DB_TABLE_NAME on $HOST_IP:$PG_ACCESSPORT Mode:$1 for $DB_USER completed:$NOW_ENDED" >>$PG_TEMP_DIR/latest.log
